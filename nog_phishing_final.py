# -*- coding: utf-8 -*-
"""nog_phishing_final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-bRu3N00yWMiRI0n9rMPbyD7dKHywcaH
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

data=pd.read_csv('phishing.csv')

data.head()

data.isna().sum()

data.describe()

data.groupby('phishing').mean()

data['phishing'].value_counts()

sns.countplot(x='phishing',data=data)

plt.figure(2)
plt.subplot(121)
sns.distplot(data['NumDots'])
plt.subplot(122)
data['NumDots'].plot.box(figsize=(15,5))

#sns.pairplot(data)

corr_matrix=data.corr()
sns.heatmap(corr_matrix)

x=data.drop(columns='phishing',axis=1)
y=data['phishing']

from sklearn.model_selection import train_test_split

x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2)

from sklearn.linear_model import LogisticRegression

lg=LogisticRegression()

lg.fit(x_train,y_train)

l_pred=lg.predict(x_test)

l_pred

from sklearn.metrics import accuracy_score

la=accuracy_score(y_test,l_pred)

from sklearn.metrics import classification_report,confusion_matrix

print(confusion_matrix(y_test,l_pred))

print(classification_report(y_test,l_pred))



from sklearn import tree
dt=tree.DecisionTreeClassifier()
dt.fit(x_train,y_train)

pred=dt.predict(x_test)
pred

from sklearn.metrics import accuracy_score

da=accuracy_score(y_test,pred)

from sklearn.ensemble import RandomForestClassifier

rf=RandomForestClassifier()

rf.fit(x_train,y_train)

r_pred=rf.predict(x_test)
r_pred

from sklearn.metrics import accuracy_score

ra=accuracy_score(y_test,r_pred)

from sklearn.neighbors import KNeighborsClassifier

neigh = KNeighborsClassifier()
neigh.fit(x_train,y_train)

kN_pred=neigh.predict(x_test)
kN_pred

from sklearn.metrics import accuracy_score

kNa=accuracy_score(y_test,kN_pred)

pred_compare=[]
pred_compare.extend([la,da,ra,kNa])
pred_names=["Logistic Regression","Decision Tree","Random Forest","       k-nearest neighbors"]

print(pred_compare)

plt.bar(pred_names,pred_compare)
plt.show()

import re
from urllib.parse import urlparse, parse_qs

def extract_features(url):
    top=[]
    for col in data.columns:
	    top.append(col)
    top.pop()
   # top.pop(0)
    print(top)
    i=0
    features = {}

    # Number of Dots
    features[top[0]] = url.count('.')

    # Subdomain Level
    parsed_url = urlparse(url)
    subdomain = parsed_url.hostname.split('.')
    features[top[1]] = len(subdomain) - 2 if len(subdomain) > 2 else 0

    # Path Level
    path = parsed_url.path.strip('/').split('/')
    features[top[2]] = len(path)

    # Url Length
    features[top[3]] = len(url)

    # Number of Dash
    features[top[4]] = url.count('-')

    # Number of Dash In Hostname
    features[top[5]] = parsed_url.hostname.count('-')

    # At Symbol
    features[top[6]] = 1 if '@' in parsed_url.netloc else 0

    # Tilde Symbol
    features[top[7]] = 1 if '~' in parsed_url.netloc else 0

    # Number of Underscore
    features[top[8]] = url.count('_')

    # Number of Percent
    features[top[9]] = url.count('%')

    # Number of QueryComponents
    features[top[10]] = len(parse_qs(parsed_url.query))

    # Number of Ampersand
    features[top[11]] = url.count('&')

    # Number of Hash
    features[top[12]] = url.count('#')

    # Number of NumericChars
    features[top[13]] = len(re.findall(r'\d', url))

    # No Https
    features[top[14]] = 1 if parsed_url.scheme != 'https' else 0

    # Random String
    features[top[15]] = 1 if parsed_url.query == '' and parsed_url.path == '/' else 0

    # IP Address
    features[top[16]] = 1 if re.match(r'\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}$', parsed_url.netloc) else 0

    # Domain In Subdomains
    domain = '.'.join(subdomain[-2:])
    features[top[17]] = 1 if domain in url else 0

    # Domain In Paths
    features[top[18]] = 1 if parsed_url.netloc in parsed_url.path else 0

    # Https In Hostname
    features[top[19]] = 1 if 'https' in parsed_url.netloc else 0

    # Hostname Length
    features[top[20]] = len(parsed_url.netloc)

    # Path Length
    features[top[21]] = sum(len(segment) for segment in path)

    # Query Length
    features[top[22]] = len(parsed_url.query)

    # Number of Double Slash In Path
    features[top[23]] = url.count('//')

    # Number of Sensitive Words
    sensitive_words = ['password', 'login', 'admin']
    features[top[24]] = sum(1 for word in sensitive_words if word in url.lower())

    return features

# Example usage
#url='	https://www.zotaregalos.com/index.html'
url='http://www.cnn..abc.com/?2016/?07/06/health/???juno-jupiter-nasa//k@ugvjh#vjh@#v$j%hvj&hv%&~jgchngchfdchgcjh~gfcjhgvjhgku/yufuyf/tfutf/jyfjhfindex.html'
#url = 'https://www.example.com/path/page?param1=value1&param2=value2'
features = extract_features(url)
for feature, value in features.items():
    print(f'{feature}: {value}')

print(features)
for feature, value in features.items():
    L=[]
    L.append(value)
    features[feature]=L

print(features)
f={"name":["gcgb"],"marks":[95]}
new = pd.DataFrame.from_dict(features)

new

u_pred=rf.predict(new)
u_pred

if u_pred[0]==0:
  print("Not a phishing site")
else:
  print("phishing site")